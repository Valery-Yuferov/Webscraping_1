
import requests
from fake_headers import Headers
import json
import pprint
from bs4 import BeautifulSoup

headers = Headers(browser="firefox", os="win")

html_data = requests.get("https://spb.hh.ru/search/vacancy?text=python&area=1&area=2", headers=headers.generate()).text

soup = BeautifulSoup(html_data, "lxml")

tag_div = soup.find_all('div', class_='serp-item')

vacancies = []

for i in tag_div:
    job_title = i.find('a', class_="serp-item__title").text
    job_city = i.find('div', attrs={'data-qa': 'vacancy-serp__vacancy-address'}).text
    job_salary = i.find('span', attrs={'data-qa': 'vacancy-serp__vacancy-compensation'}).text
    job_company = i.find('a', attrs={'data-qa': 'vacancy-serp__vacancy-employer'}).text
    job_link = i.find('a', class_="serp-item__title")['href']

    if 'Django' or 'Flask' in job_title:
        vacancy_info = {
            'Вакансия': job_title,
            'Город': job_city,
            'Зарплата': job_salary,
            'Компания': job_company,
            'Ссылка': job_link
                    }
        vacancies.append(vacancy_info)

pprint.pprint(vacancies)

with open('vacancies.json', 'w', encoding='utf-8') as json_file:
    json.dump(vacancies, json_file)
    
